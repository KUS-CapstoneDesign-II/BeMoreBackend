<!--
카메라 + 음성(STT) + 얼굴 랜드마크 통합 테스트용 프론트엔드
-->

<!DOCTYPE html>
<html lang="ko">
  <head>
    <meta charset="UTF-8" />
    <title>Emotion Analyzer Demo</title>
    <style>
      video,
      canvas {
        position: absolute;
        top: 0;
        left: 0;
        transform: scaleX(-1);
      }

      #status {
        position: fixed;
        top: 10px;
        left: 10px;
        background: rgba(0, 0, 0, 0.7);
        color: white;
        padding: 10px;
        border-radius: 8px;
        font-family: sans-serif;
        z-index: 10;
      }
    </style>
  </head>
  <body>
    <div id="status">🎥 초기화 중...</div>
    <video id="input_video" autoplay playsinline></video>
    <canvas id="output_canvas"></canvas>

    <!-- Mediapipe 라이브러리 -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

    <script>
      const statusDiv = document.getElementById("status");
      const videoElement = document.getElementById("input_video");
      const canvasElement = document.getElementById("output_canvas");
      const canvasCtx = canvasElement.getContext("2d");

      // ====== WebSocket 연결 ======
      const ws = new WebSocket("ws://localhost:8000");
      ws.onopen = () => (statusDiv.textContent = "✅ WebSocket 연결 완료");
      ws.onmessage = (msg) => {
        try {
          const data = JSON.parse(msg.data);
          if (data.emotion) {
            statusDiv.textContent = `😃 감정: ${data.emotion}`;
          }
        } catch {}
      };

      // ====== Mediapipe FaceMesh 설정 ======
      const faceMesh = new FaceMesh({
        locateFile: (file) =>
          `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
      });

      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5,
      });

      let frameCount = 0;
      faceMesh.onResults((results) => {
        canvasElement.width = videoElement.videoWidth;
        canvasElement.height = videoElement.videoHeight;
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        canvasCtx.drawImage(
          results.image,
          0,
          0,
          canvasElement.width,
          canvasElement.height
        );

        if (results.multiFaceLandmarks) {
          for (const landmarks of results.multiFaceLandmarks) {
            for (const point of landmarks) {
              const x = point.x * canvasElement.width;
              const y = point.y * canvasElement.height;
              canvasCtx.beginPath();
              canvasCtx.arc(x, y, 1.5, 0, 2 * Math.PI);
              canvasCtx.fillStyle = "red";
              canvasCtx.fill();
            }
          }

          frameCount++;
          if (frameCount % 3 === 0 && ws.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify(results.multiFaceLandmarks));
          }
        }
      });

      // ====== 카메라 시작 ======
      const camera = new Camera(videoElement, {
        onFrame: async () => await faceMesh.send({ image: videoElement }),
        width: 640,
        height: 480,
      });
      camera.start();

      // ====== 마이크 녹음 및 STT 전송 ======
      let mediaRecorder;
      let audioChunks = [];

      async function startMicRecording() {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // mimeType 명시
        mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm; codecs=opus" });

        mediaRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) {
            audioChunks.push(e.data);
          }
        };

        // 5초 단위로 자동 전송
        setInterval(async () => {
          if (audioChunks.length === 0) return;

          const blob = new Blob(audioChunks, { type: "audio/webm; codecs=opus" });
          audioChunks = [];

          if (blob.size === 0) return; // 빈 오디오 전송 방지

          if (blob.size < 500) return; // 너무 작은 파일 무시


          const formData = new FormData();
          formData.append("audio", blob, `speech_${Date.now()}.webm`);

          try {
            const res = await fetch("/api/transcribe", {
              method: "POST",
              body: formData,
            });
            const data = await res.json();
            console.log("🗣️ STT 결과:", data.text);
          } catch (err) {
            console.error("STT 업로드 실패:", err);
          }
        }, 5000);

        mediaRecorder.start(1000); // 1초 단위 chunk
        statusDiv.textContent = "🎤 음성 녹음 중 + 얼굴 추적 중";
      }

      startMicRecording().catch((err) => {
        statusDiv.textContent = "🚫 마이크 접근 실패: " + err.message;
      });
    </script>
  </body>
</html>
