# ğŸ¤ Frontend AI Voice Chat Integration Guide

**ì‘ì„±ì¼**: 2025-01-14
**ëŒ€ìƒ**: Frontend ê°œë°œì (React + TypeScript)
**ë°±ì—”ë“œ ìƒíƒœ**: âœ… ì™„ì „ êµ¬í˜„ ì™„ë£Œ (í”„ë¡œë•ì…˜ ë ˆë””)

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ë°±ì—”ë“œ êµ¬í˜„ í˜„í™©](#ë°±ì—”ë“œ-êµ¬í˜„-í˜„í™©)
3. [WebSocket API ìŠ¤í™](#websocket-api-ìŠ¤í™)
4. [React í†µí•© êµ¬í˜„](#react-í†µí•©-êµ¬í˜„)
5. [TTS ì—°ë™](#tts-ì—°ë™)
6. [ì—ëŸ¬ í•¸ë“¤ë§](#ì—ëŸ¬-í•¸ë“¤ë§)
7. [í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ](#í…ŒìŠ¤íŠ¸-ê°€ì´ë“œ)
8. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ê°œìš”

**ì¢‹ì€ ì†Œì‹**: AI ìŒì„± ìƒë‹´ ê¸°ëŠ¥ì´ ë°±ì—”ë“œì— **ì´ë¯¸ 100% êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!**

í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í•´ì•¼ í•  ì¼:
1. âœ… WebSocket ì—°ê²° (ì´ë¯¸ ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ)
2. ğŸ†• `request_ai_response` ë©”ì‹œì§€ ì „ì†¡ ì¶”ê°€
3. ğŸ†• ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìˆ˜ì‹  ë° UI í‘œì‹œ
4. ğŸ†• TTSë¡œ ìŒì„± ì¬ìƒ

**ì˜ˆìƒ êµ¬í˜„ ì‹œê°„**: 2-3ì‹œê°„

---

## ë°±ì—”ë“œ êµ¬í˜„ í˜„í™©

### âœ… ì´ë¯¸ ì™„ë£Œëœ ê¸°ëŠ¥

| ê¸°ëŠ¥ | ìƒíƒœ | ìœ„ì¹˜ |
|------|------|------|
| **Gemini API ìŠ¤íŠ¸ë¦¬ë°** | âœ… ì™„ë£Œ | `services/gemini/gemini.js` |
| **WebSocket í•¸ë“¤ëŸ¬** | âœ… ì™„ë£Œ | `services/socket/sessionHandler.js` |
| **ê°ì • ê¸°ë°˜ í”„ë¡¬í”„íŠ¸** | âœ… ì™„ë£Œ | 8ê°œ ê°ì • ì§€ì› |
| **ëŒ€í™” íˆìŠ¤í† ë¦¬** | âœ… ì™„ë£Œ | PostgreSQL ì €ì¥ (ìµœê·¼ 10ê°œ) |
| **ì—ëŸ¬ í•¸ë“¤ë§** | âœ… ì™„ë£Œ | íƒ€ì„ì•„ì›ƒ, ê²€ì¦ í¬í•¨ |

### ì§€ì›í•˜ëŠ” ê°ì • (8ê°€ì§€)

```typescript
type Emotion =
  | 'happy'      // í–‰ë³µ
  | 'sad'        // ìŠ¬í””
  | 'angry'      // ë¶„ë…¸
  | 'anxious'    // ë¶ˆì•ˆ
  | 'neutral'    // ì¤‘ë¦½
  | 'surprised'  // ë†€ëŒ
  | 'disgusted'  // í˜ì˜¤
  | 'fearful';   // ë‘ë ¤ì›€
```

---

## WebSocket API ìŠ¤í™

### Endpoint

```typescript
const wsUrl = `ws://${BACKEND_URL}/ws/session/${sessionId}`;
```

**ì¸ì¦**: JWT í† í° (ê¸°ì¡´ WebSocket ì—°ê²° ë°©ì‹ê³¼ ë™ì¼)

---

### ë©”ì‹œì§€ íƒ€ì…

#### 1ï¸âƒ£ ìš”ì²­: AI ì‘ë‹µ ìƒì„±

**Frontend â†’ Backend**

```typescript
interface AIRequestMessage {
  type: 'request_ai_response';
  data: {
    message: string;           // ì‚¬ìš©ì ë©”ì‹œì§€ (1~2000ì)
    emotion: Emotion | null;   // í˜„ì¬ ê°ì • (ì„ íƒ)
  };
}
```

**ì˜ˆì œ**:
```typescript
ws.send(JSON.stringify({
  type: 'request_ai_response',
  data: {
    message: 'ìš”ì¦˜ íšŒì‚¬ì—ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ì•„ìš”',
    emotion: 'anxious'
  }
}));
```

---

#### 2ï¸âƒ£ ì‘ë‹µ: ìŠ¤íŠ¸ë¦¬ë° (3ë‹¨ê³„)

**Backend â†’ Frontend**

##### â‘  ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘

```typescript
interface AIStreamBeginMessage {
  type: 'ai_stream_begin';
  data: {};
}
```

**í”„ë¡ íŠ¸ì—”ë“œ ì²˜ë¦¬**:
- ë¡œë”© UI í‘œì‹œ
- ì‘ë‹µ ë²„í¼ ì´ˆê¸°í™”
- ê¸°ì¡´ ë©”ì‹œì§€ ì ê¸ˆ

---

##### â‘¡ ì‘ë‹µ ì²­í¬ (ì—¬ëŸ¬ ë²ˆ)

```typescript
interface AIStreamChunkMessage {
  type: 'ai_stream_chunk';
  data: {
    chunk: string;  // âš ï¸ í•„ë“œëª… "chunk" í•„ìˆ˜!
  };
}
```

**ìˆ˜ì‹  ë¹ˆë„**: í‰ê·  50-100ms ê°„ê²©

**í”„ë¡ íŠ¸ì—”ë“œ ì²˜ë¦¬**:
- í…ìŠ¤íŠ¸ ëˆ„ì  í‘œì‹œ (íƒ€ì´í•‘ íš¨ê³¼)
- TTS ì—”ì§„ì— ì²­í¬ ì „ë‹¬
- ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸

âš ï¸ **ì¤‘ìš”**: í•„ë“œëª…ì€ ë°˜ë“œì‹œ `chunk`ì…ë‹ˆë‹¤ (`text` ì•„ë‹˜!)

---

##### â‘¢ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ

```typescript
interface AIStreamCompleteMessage {
  type: 'ai_stream_complete';
  data: {};
}
```

**í”„ë¡ íŠ¸ì—”ë“œ ì²˜ë¦¬**:
- ë¡œë”© UI ìˆ¨ê¹€
- ìµœì¢… ë©”ì‹œì§€ í™•ì •
- ì‚¬ìš©ì ì…ë ¥ ì¬í™œì„±í™”
- TTS ì¢…ë£Œ ëŒ€ê¸°

---

#### 3ï¸âƒ£ ì—ëŸ¬ ì²˜ë¦¬

```typescript
interface AIStreamErrorMessage {
  type: 'ai_stream_error';
  data: {
    error: string;  // ì—ëŸ¬ ë©”ì‹œì§€
  };
}
```

**ì—ëŸ¬ ìœ í˜•**:
- `"ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"` - ë¹ˆ ë©”ì‹œì§€ ì „ì†¡
- `"ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 2000ì)"` - ê¸¸ì´ ì´ˆê³¼
- `"AI ì‘ë‹µ ì‹œê°„ ì´ˆê³¼ (45ì´ˆ)"` - íƒ€ì„ì•„ì›ƒ
- `"AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"` - API ì—ëŸ¬

---

## React í†µí•© êµ¬í˜„

### íƒ€ì… ì •ì˜ (`types/ai-chat.ts`)

```typescript
// ê°ì • íƒ€ì…
export type Emotion =
  | 'happy' | 'sad' | 'angry' | 'anxious'
  | 'neutral' | 'surprised' | 'disgusted' | 'fearful';

// ë©”ì‹œì§€ íƒ€ì…
export interface ChatMessage {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  emotion?: Emotion;
  timestamp: number;
  isStreaming?: boolean;
}

// WebSocket ë©”ì‹œì§€ íƒ€ì…
export type WSMessage =
  | { type: 'request_ai_response'; data: { message: string; emotion: Emotion | null } }
  | { type: 'ai_stream_begin'; data: {} }
  | { type: 'ai_stream_chunk'; data: { chunk: string } }
  | { type: 'ai_stream_complete'; data: {} }
  | { type: 'ai_stream_error'; data: { error: string } };
```

---

### Custom Hook (`hooks/useAIVoiceChat.ts`)

```typescript
import { useState, useCallback, useRef, useEffect } from 'react';
import type { ChatMessage, Emotion, WSMessage } from '../types/ai-chat';

interface UseAIVoiceChatProps {
  sessionId: string;
  ws: WebSocket | null;  // ê¸°ì¡´ WebSocket ì—°ê²°
  onError?: (error: string) => void;
  onChunk?: (chunk: string) => void;  // TTS ì—°ë™ìš©
}

export function useAIVoiceChat({
  sessionId,
  ws,
  onError,
  onChunk
}: UseAIVoiceChatProps) {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [isStreaming, setIsStreaming] = useState(false);
  const [currentResponse, setCurrentResponse] = useState('');
  const currentMessageIdRef = useRef<string>('');

  // WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  í•¸ë“¤ëŸ¬
  useEffect(() => {
    if (!ws) return;

    const handleMessage = (event: MessageEvent) => {
      const message: WSMessage = JSON.parse(event.data);

      switch (message.type) {
        case 'ai_stream_begin':
          // ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
          setIsStreaming(true);
          setCurrentResponse('');
          currentMessageIdRef.current = `ai_${Date.now()}`;
          break;

        case 'ai_stream_chunk':
          // ì²­í¬ ìˆ˜ì‹ 
          const { chunk } = message.data;
          setCurrentResponse((prev) => prev + chunk);

          // TTS ì—°ë™
          if (onChunk) {
            onChunk(chunk);
          }
          break;

        case 'ai_stream_complete':
          // ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
          setIsStreaming(false);

          // ìµœì¢… ë©”ì‹œì§€ ì €ì¥
          setMessages((prev) => [
            ...prev,
            {
              id: currentMessageIdRef.current,
              role: 'assistant',
              content: currentResponse,
              timestamp: Date.now()
            }
          ]);

          setCurrentResponse('');
          break;

        case 'ai_stream_error':
          // ì—ëŸ¬ ì²˜ë¦¬
          setIsStreaming(false);
          setCurrentResponse('');

          if (onError) {
            onError(message.data.error);
          }

          console.error('[AI Stream Error]', message.data.error);
          break;
      }
    };

    ws.addEventListener('message', handleMessage);

    return () => {
      ws.removeEventListener('message', handleMessage);
    };
  }, [ws, currentResponse, onChunk, onError]);

  // AI ì‘ë‹µ ìš”ì²­
  const requestAIResponse = useCallback(
    (userMessage: string, emotion: Emotion | null = null) => {
      if (!ws || ws.readyState !== WebSocket.OPEN) {
        console.error('[AI Chat] WebSocket not connected');
        return;
      }

      if (!userMessage.trim()) {
        console.error('[AI Chat] Empty message');
        return;
      }

      if (userMessage.length > 2000) {
        console.error('[AI Chat] Message too long');
        if (onError) {
          onError('ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 2000ì)');
        }
        return;
      }

      // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
      const userMsgId = `user_${Date.now()}`;
      setMessages((prev) => [
        ...prev,
        {
          id: userMsgId,
          role: 'user',
          content: userMessage,
          emotion: emotion || undefined,
          timestamp: Date.now()
        }
      ]);

      // AI ìš”ì²­ ì „ì†¡
      ws.send(
        JSON.stringify({
          type: 'request_ai_response',
          data: {
            message: userMessage,
            emotion
          }
        })
      );

      console.log('[AI Chat] Request sent:', { message: userMessage, emotion });
    },
    [ws, onError]
  );

  // ëŒ€í™” ì´ˆê¸°í™”
  const clearMessages = useCallback(() => {
    setMessages([]);
    setCurrentResponse('');
    setIsStreaming(false);
  }, []);

  return {
    messages,
    isStreaming,
    currentResponse,
    requestAIResponse,
    clearMessages
  };
}
```

---

### ì»´í¬ë„ŒíŠ¸ ì˜ˆì œ (`components/AIVoiceChat.tsx`)

```typescript
import React, { useState } from 'react';
import { useAIVoiceChat } from '../hooks/useAIVoiceChat';
import type { Emotion } from '../types/ai-chat';

interface AIVoiceChatProps {
  sessionId: string;
  ws: WebSocket | null;
  currentEmotion: Emotion | null;  // ì–¼êµ´ ê°ì • ë¶„ì„ ê²°ê³¼
  onTTSChunk?: (chunk: string) => void;  // TTS ì—”ì§„ ì—°ë™
}

export function AIVoiceChat({
  sessionId,
  ws,
  currentEmotion,
  onTTSChunk
}: AIVoiceChatProps) {
  const [inputMessage, setInputMessage] = useState('');
  const [error, setError] = useState<string | null>(null);

  const {
    messages,
    isStreaming,
    currentResponse,
    requestAIResponse,
    clearMessages
  } = useAIVoiceChat({
    sessionId,
    ws,
    onError: setError,
    onChunk: onTTSChunk
  });

  const handleSendMessage = (e: React.FormEvent) => {
    e.preventDefault();

    if (!inputMessage.trim() || isStreaming) {
      return;
    }

    requestAIResponse(inputMessage, currentEmotion);
    setInputMessage('');
    setError(null);
  };

  return (
    <div className="ai-voice-chat">
      {/* ëŒ€í™” ë‚´ì—­ */}
      <div className="chat-messages">
        {messages.map((msg) => (
          <div
            key={msg.id}
            className={`message message-${msg.role}`}
            data-emotion={msg.emotion}
          >
            <div className="message-content">{msg.content}</div>
            <div className="message-meta">
              {msg.emotion && (
                <span className="emotion-badge">{msg.emotion}</span>
              )}
              <span className="timestamp">
                {new Date(msg.timestamp).toLocaleTimeString()}
              </span>
            </div>
          </div>
        ))}

        {/* ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ ì‘ë‹µ */}
        {isStreaming && (
          <div className="message message-assistant streaming">
            <div className="message-content">
              {currentResponse}
              <span className="cursor">â–‹</span>
            </div>
            <div className="message-meta">
              <span className="streaming-indicator">ì‘ë‹µ ìƒì„± ì¤‘...</span>
            </div>
          </div>
        )}
      </div>

      {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
      {error && (
        <div className="error-banner">
          <span className="error-icon">âš ï¸</span>
          {error}
          <button onClick={() => setError(null)}>Ã—</button>
        </div>
      )}

      {/* ì…ë ¥ í¼ */}
      <form onSubmit={handleSendMessage} className="chat-input-form">
        <input
          type="text"
          value={inputMessage}
          onChange={(e) => setInputMessage(e.target.value)}
          placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
          disabled={isStreaming}
          maxLength={2000}
          className="chat-input"
        />

        <button
          type="submit"
          disabled={!inputMessage.trim() || isStreaming}
          className="send-button"
        >
          {isStreaming ? 'ì „ì†¡ ì¤‘...' : 'ì „ì†¡'}
        </button>

        {/* í˜„ì¬ ê°ì • í‘œì‹œ */}
        {currentEmotion && (
          <div className="current-emotion">
            ê°ì •: <strong>{currentEmotion}</strong>
          </div>
        )}
      </form>

      {/* ë””ë²„ê·¸ ì •ë³´ (ê°œë°œ ì¤‘ì—ë§Œ) */}
      {process.env.NODE_ENV === 'development' && (
        <div className="debug-info">
          <p>WebSocket: {ws ? 'Connected' : 'Disconnected'}</p>
          <p>Streaming: {isStreaming ? 'Yes' : 'No'}</p>
          <p>Messages: {messages.length}</p>
          <button onClick={clearMessages}>Clear Messages</button>
        </div>
      )}
    </div>
  );
}
```

---

### ìŠ¤íƒ€ì¼ ì˜ˆì œ (`AIVoiceChat.css`)

```css
.ai-voice-chat {
  display: flex;
  flex-direction: column;
  height: 100%;
  max-width: 800px;
  margin: 0 auto;
}

/* ëŒ€í™” ë‚´ì—­ */
.chat-messages {
  flex: 1;
  overflow-y: auto;
  padding: 20px;
  display: flex;
  flex-direction: column;
  gap: 16px;
}

/* ë©”ì‹œì§€ */
.message {
  padding: 12px 16px;
  border-radius: 12px;
  max-width: 70%;
  animation: fadeIn 0.3s ease-in;
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.message-user {
  align-self: flex-end;
  background: #007bff;
  color: white;
}

.message-assistant {
  align-self: flex-start;
  background: #f0f0f0;
  color: #333;
}

/* ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ */
.message.streaming {
  background: #e8f5e9;
  border: 2px dashed #4caf50;
}

.message.streaming .cursor {
  animation: blink 1s infinite;
}

@keyframes blink {
  0%, 50% { opacity: 1; }
  51%, 100% { opacity: 0; }
}

/* ë©”ì‹œì§€ ë©”íƒ€ ì •ë³´ */
.message-meta {
  display: flex;
  gap: 8px;
  align-items: center;
  margin-top: 4px;
  font-size: 12px;
  opacity: 0.7;
}

.emotion-badge {
  padding: 2px 8px;
  background: rgba(0, 0, 0, 0.1);
  border-radius: 4px;
  font-weight: 500;
}

/* ì—ëŸ¬ ë°°ë„ˆ */
.error-banner {
  background: #ffebee;
  border: 1px solid #f44336;
  padding: 12px 16px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  gap: 8px;
  margin: 16px 20px;
  animation: slideDown 0.3s ease-out;
}

@keyframes slideDown {
  from {
    opacity: 0;
    transform: translateY(-10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.error-icon {
  font-size: 20px;
}

.error-banner button {
  margin-left: auto;
  background: none;
  border: none;
  font-size: 20px;
  cursor: pointer;
  color: #f44336;
}

/* ì…ë ¥ í¼ */
.chat-input-form {
  display: flex;
  gap: 8px;
  padding: 20px;
  border-top: 1px solid #e0e0e0;
  background: white;
}

.chat-input {
  flex: 1;
  padding: 12px 16px;
  border: 1px solid #ddd;
  border-radius: 24px;
  font-size: 14px;
  outline: none;
}

.chat-input:focus {
  border-color: #007bff;
  box-shadow: 0 0 0 3px rgba(0, 123, 255, 0.1);
}

.chat-input:disabled {
  background: #f5f5f5;
  cursor: not-allowed;
}

.send-button {
  padding: 12px 24px;
  background: #007bff;
  color: white;
  border: none;
  border-radius: 24px;
  font-weight: 500;
  cursor: pointer;
  transition: background 0.2s;
}

.send-button:hover:not(:disabled) {
  background: #0056b3;
}

.send-button:disabled {
  background: #ccc;
  cursor: not-allowed;
}

.current-emotion {
  padding: 8px 16px;
  background: #e3f2fd;
  border-radius: 16px;
  font-size: 14px;
  white-space: nowrap;
}
```

---

## TTS ì—°ë™

### ì˜µì…˜ 1: Web Speech API (ë¸Œë¼ìš°ì € ê¸°ë³¸)

```typescript
// TTS ì„œë¹„ìŠ¤ (`services/tts.ts`)
export class TTSService {
  private synthesis: SpeechSynthesis;
  private utterance: SpeechSynthesisUtterance | null = null;
  private queue: string[] = [];
  private isSpeaking = false;

  constructor() {
    this.synthesis = window.speechSynthesis;
  }

  // ì²­í¬ ë‹¨ìœ„ ìŒì„± ì¬ìƒ
  speakChunk(chunk: string) {
    this.queue.push(chunk);
    this.processQueue();
  }

  private async processQueue() {
    if (this.isSpeaking || this.queue.length === 0) {
      return;
    }

    this.isSpeaking = true;
    const text = this.queue.shift()!;

    this.utterance = new SpeechSynthesisUtterance(text);
    this.utterance.lang = 'ko-KR';
    this.utterance.rate = 1.0;
    this.utterance.pitch = 1.0;

    this.utterance.onend = () => {
      this.isSpeaking = false;
      this.processQueue();
    };

    this.synthesis.speak(this.utterance);
  }

  // ì¤‘ì§€
  stop() {
    this.synthesis.cancel();
    this.queue = [];
    this.isSpeaking = false;
  }

  // ì§€ì› ì—¬ë¶€ í™•ì¸
  static isSupported(): boolean {
    return 'speechSynthesis' in window;
  }
}
```

**ì‚¬ìš© ì˜ˆì œ**:
```typescript
const ttsService = new TTSService();

const { requestAIResponse } = useAIVoiceChat({
  sessionId,
  ws,
  onChunk: (chunk) => {
    ttsService.speakChunk(chunk);  // ì‹¤ì‹œê°„ ìŒì„± ì¬ìƒ
  }
});
```

---

### ì˜µì…˜ 2: ì™¸ë¶€ TTS API (ElevenLabs, Google TTS ë“±)

```typescript
// ì²­í¬ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° TTS
async function streamTTS(text: string, onAudio: (audioData: ArrayBuffer) => void) {
  const response = await fetch('https://api.elevenlabs.io/v1/text-to-speech/voice-id/stream', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'xi-api-key': ELEVENLABS_API_KEY
    },
    body: JSON.stringify({
      text,
      model_id: 'eleven_multilingual_v2',
      voice_settings: {
        stability: 0.5,
        similarity_boost: 0.75
      }
    })
  });

  const reader = response.body?.getReader();
  if (!reader) return;

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    onAudio(value.buffer);
  }
}
```

---

## ì—ëŸ¬ í•¸ë“¤ë§

### ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ ë° ì²˜ë¦¬ ë°©ë²•

```typescript
// ì—ëŸ¬ í•¸ë“¤ëŸ¬ (`utils/ai-error-handler.ts`)
export interface AIError {
  type: 'network' | 'validation' | 'timeout' | 'server' | 'unknown';
  message: string;
  retryable: boolean;
}

export function handleAIError(error: string): AIError {
  if (error.includes('ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤')) {
    return {
      type: 'validation',
      message: 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”',
      retryable: false
    };
  }

  if (error.includes('ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤')) {
    return {
      type: 'validation',
      message: 'ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 2000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”',
      retryable: false
    };
  }

  if (error.includes('ì‹œê°„ ì´ˆê³¼')) {
    return {
      type: 'timeout',
      message: 'AI ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”',
      retryable: true
    };
  }

  if (error.includes('ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')) {
    return {
      type: 'server',
      message: 'AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”',
      retryable: true
    };
  }

  return {
    type: 'unknown',
    message: error || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
    retryable: true
  };
}

// ì¬ì‹œë„ ë¡œì§
export async function retryAIRequest(
  requestFn: () => void,
  maxRetries = 3,
  delayMs = 1000
): Promise<void> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      requestFn();
      return;
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise((resolve) => setTimeout(resolve, delayMs * (i + 1)));
    }
  }
}
```

---

## í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### 1. ë¡œì»¬ í…ŒìŠ¤íŠ¸

#### ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰
```bash
# BeMoreBackend ë””ë ‰í† ë¦¬ì—ì„œ
npm run dev
```

#### í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ ì„œë²„ ì‹¤í–‰
```bash
# BeMoreFrontend ë””ë ‰í† ë¦¬ì—ì„œ
npm run dev
```

#### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

**ì‹œë‚˜ë¦¬ì˜¤ 1: ê¸°ë³¸ ëŒ€í™”**
1. ì„¸ì…˜ ì‹œì‘
2. WebSocket ì—°ê²° í™•ì¸
3. ë©”ì‹œì§€ ì…ë ¥: "ì•ˆë…•í•˜ì„¸ìš”"
4. AI ì‘ë‹µ í™•ì¸ (ìŠ¤íŠ¸ë¦¬ë°)
5. TTS ìŒì„± ì¬ìƒ í™•ì¸

**ì‹œë‚˜ë¦¬ì˜¤ 2: ê°ì • ê¸°ë°˜ ì‘ë‹µ**
1. ê°ì • ë¶„ì„ í™œì„±í™” (ì–¼êµ´ ì¸ì‹)
2. ê°ì • ìƒíƒœ: "sad"
3. ë©”ì‹œì§€: "ìš”ì¦˜ ìš°ìš¸í•´ìš”"
4. AI ì‘ë‹µ í†¤ í™•ì¸ (ê³µê°ì , ìœ„ë¡œ)

**ì‹œë‚˜ë¦¬ì˜¤ 3: ì—ëŸ¬ ì²˜ë¦¬**
1. ë¹ˆ ë©”ì‹œì§€ ì „ì†¡ â†’ ì—ëŸ¬ í™•ì¸
2. 2000ì ì´ˆê³¼ ë©”ì‹œì§€ â†’ ì—ëŸ¬ í™•ì¸
3. WebSocket ì—°ê²° ëŠê¹€ â†’ ì¬ì—°ê²°

---

### 2. ê°œë°œì ë„êµ¬ í™•ì¸

**Chrome DevTools â†’ Network â†’ WS**

ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ í™•ì¸:
```
â†’ {"type":"request_ai_response","data":{"message":"ì•ˆë…•í•˜ì„¸ìš”","emotion":"neutral"}}
â† {"type":"ai_stream_begin","data":{}}
â† {"type":"ai_stream_chunk","data":{"chunk":"ì•ˆë…•í•˜ì„¸ìš”! "}}
â† {"type":"ai_stream_chunk","data":{"chunk":"ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë– ì„¸ìš”?"}}
â† {"type":"ai_stream_complete","data":{}}
```

---

### 3. ìë™ í…ŒìŠ¤íŠ¸ (Jest + React Testing Library)

```typescript
// __tests__/AIVoiceChat.test.tsx
import { render, fireEvent, waitFor } from '@testing-library/react';
import { AIVoiceChat } from '../components/AIVoiceChat';

describe('AIVoiceChat', () => {
  let mockWs: any;

  beforeEach(() => {
    mockWs = {
      readyState: WebSocket.OPEN,
      send: jest.fn(),
      addEventListener: jest.fn(),
      removeEventListener: jest.fn()
    };
  });

  it('should send AI request on form submit', () => {
    const { getByPlaceholderText, getByText } = render(
      <AIVoiceChat
        sessionId="test-session"
        ws={mockWs}
        currentEmotion="neutral"
      />
    );

    const input = getByPlaceholderText('ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...');
    const sendButton = getByText('ì „ì†¡');

    fireEvent.change(input, { target: { value: 'ì•ˆë…•í•˜ì„¸ìš”' } });
    fireEvent.click(sendButton);

    expect(mockWs.send).toHaveBeenCalledWith(
      JSON.stringify({
        type: 'request_ai_response',
        data: {
          message: 'ì•ˆë…•í•˜ì„¸ìš”',
          emotion: 'neutral'
        }
      })
    );
  });

  it('should display streaming response', async () => {
    const { getByText } = render(
      <AIVoiceChat
        sessionId="test-session"
        ws={mockWs}
        currentEmotion={null}
      />
    );

    // Simulate streaming messages
    const messageHandler = mockWs.addEventListener.mock.calls[0][1];

    messageHandler({ data: JSON.stringify({ type: 'ai_stream_begin', data: {} }) });
    messageHandler({ data: JSON.stringify({ type: 'ai_stream_chunk', data: { chunk: 'ì•ˆë…•í•˜ì„¸ìš” ' } }) });
    messageHandler({ data: JSON.stringify({ type: 'ai_stream_chunk', data: { chunk: 'ë°˜ê°‘ìŠµë‹ˆë‹¤' } }) });

    await waitFor(() => {
      expect(getByText(/ì•ˆë…•í•˜ì„¸ìš” ë°˜ê°‘ìŠµë‹ˆë‹¤/)).toBeInTheDocument();
    });

    messageHandler({ data: JSON.stringify({ type: 'ai_stream_complete', data: {} }) });

    await waitFor(() => {
      expect(getByText('ì•ˆë…•í•˜ì„¸ìš” ë°˜ê°‘ìŠµë‹ˆë‹¤')).toBeInTheDocument();
    });
  });
});
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Q1: AI ì‘ë‹µì´ ì˜¤ì§€ ì•ŠìŒ

**ì¦ìƒ**: `ai_stream_begin` í›„ ë¬´í•œ ëŒ€ê¸°

**í™•ì¸ ì‚¬í•­**:
1. WebSocket ì—°ê²° ìƒíƒœ í™•ì¸
   ```typescript
   console.log('WS State:', ws.readyState); // 1 = OPEN
   ```

2. ë°±ì—”ë“œ ë¡œê·¸ í™•ì¸
   ```bash
   # Backend í„°ë¯¸ë„ì—ì„œ
   # "AI Request" ë¡œê·¸ê°€ ë³´ì´ëŠ”ì§€ í™•ì¸
   ```

3. ë„¤íŠ¸ì›Œí¬ íƒ­ì—ì„œ WebSocket ë©”ì‹œì§€ í™•ì¸

**í•´ê²° ë°©ë²•**:
- WebSocket ì¬ì—°ê²°
- ë°±ì—”ë“œ ì„œë²„ ì¬ì‹œì‘
- Gemini API í‚¤ í™•ì¸ (.env)

---

### Q2: ìŠ¤íŠ¸ë¦¬ë°ì´ ì¤‘ê°„ì— ë©ˆì¶¤

**ì¦ìƒ**: ì¼ë¶€ ì²­í¬ë§Œ ë°›ê³  ë©ˆì¶¤

**í™•ì¸ ì‚¬í•­**:
1. WebSocket heartbeat í™•ì¸
2. ë¸Œë¼ìš°ì € ì½˜ì†” ì—ëŸ¬ í™•ì¸
3. ë°±ì—”ë“œ íƒ€ì„ì•„ì›ƒ ë¡œê·¸ í™•ì¸

**í•´ê²° ë°©ë²•**:
```typescript
// WebSocket ì¬ì—°ê²° ë¡œì§
useEffect(() => {
  let reconnectTimeout: NodeJS.Timeout;

  const handleClose = () => {
    console.log('WebSocket closed, reconnecting in 3s...');
    reconnectTimeout = setTimeout(() => {
      // ì¬ì—°ê²° ë¡œì§
    }, 3000);
  };

  ws?.addEventListener('close', handleClose);

  return () => {
    ws?.removeEventListener('close', handleClose);
    clearTimeout(reconnectTimeout);
  };
}, [ws]);
```

---

### Q3: TTSê°€ ì‘ë™í•˜ì§€ ì•ŠìŒ

**ì¦ìƒ**: í…ìŠ¤íŠ¸ëŠ” í‘œì‹œë˜ì§€ë§Œ ìŒì„±ì´ ë‚˜ì˜¤ì§€ ì•ŠìŒ

**í™•ì¸ ì‚¬í•­**:
1. Web Speech API ì§€ì› í™•ì¸
   ```typescript
   if (!TTSService.isSupported()) {
     console.error('TTS not supported in this browser');
   }
   ```

2. ë¸Œë¼ìš°ì € ìŒì†Œê±° í•´ì œ
3. HTTPS ì—°ê²° í™•ì¸ (ì¼ë¶€ ë¸Œë¼ìš°ì €ëŠ” HTTPS í•„ìˆ˜)

**í•´ê²° ë°©ë²•**:
```typescript
// ì‚¬ìš©ì ì¸í„°ë™ì…˜ í›„ TTS ì´ˆê¸°í™”
const initTTS = () => {
  if (TTSService.isSupported()) {
    ttsService = new TTSService();
    console.log('TTS initialized');
  } else {
    alert('ì´ ë¸Œë¼ìš°ì €ëŠ” TTSë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤');
  }
};

// ë²„íŠ¼ í´ë¦­ ì‹œ ì´ˆê¸°í™”
<button onClick={initTTS}>TTS í™œì„±í™”</button>
```

---

### Q4: í•œêµ­ì–´ ì¸ì½”ë”© ë¬¸ì œ

**ì¦ìƒ**: AI ì‘ë‹µì— ê¹¨ì§„ ë¬¸ì

**í™•ì¸ ì‚¬í•­**:
1. WebSocket ì¸ì½”ë”© í™•ì¸
2. ì‘ë‹µ íŒŒì‹± í™•ì¸

**í•´ê²° ë°©ë²•**:
```typescript
// WebSocket ë©”ì‹œì§€ íŒŒì‹± ì‹œ UTF-8 ëª…ì‹œ
const message = JSON.parse(event.data);
// event.dataëŠ” ìë™ìœ¼ë¡œ UTF-8 ë””ì½”ë”©ë¨
```

---

### Q5: ì„±ëŠ¥ ì €í•˜ (ëŠë¦° UI)

**ì¦ìƒ**: ë§ì€ ë©”ì‹œì§€ í›„ UIê°€ ëŠë ¤ì§

**í•´ê²° ë°©ë²•**:
```typescript
// ë©”ì‹œì§€ ê°œìˆ˜ ì œí•œ
const MAX_MESSAGES = 50;

setMessages((prev) => {
  const newMessages = [...prev, newMessage];
  if (newMessages.length > MAX_MESSAGES) {
    return newMessages.slice(-MAX_MESSAGES);
  }
  return newMessages;
});

// ê°€ìƒí™” (react-window)
import { FixedSizeList } from 'react-window';

<FixedSizeList
  height={600}
  itemCount={messages.length}
  itemSize={80}
  width="100%"
>
  {({ index, style }) => (
    <div style={style}>
      <Message message={messages[index]} />
    </div>
  )}
</FixedSizeList>
```

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„ ì „
- [ ] ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ í™•ì¸ (`http://localhost:3000/api/health`)
- [ ] WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸
- [ ] ê¸°ì¡´ ì„¸ì…˜ ê´€ë¦¬ ì½”ë“œ í™•ì¸

### êµ¬í˜„ ì¤‘
- [ ] íƒ€ì… ì •ì˜ ì‘ì„± (`types/ai-chat.ts`)
- [ ] Custom Hook ì‘ì„± (`hooks/useAIVoiceChat.ts`)
- [ ] UI ì»´í¬ë„ŒíŠ¸ ì‘ì„± (`components/AIVoiceChat.tsx`)
- [ ] TTS ì„œë¹„ìŠ¤ í†µí•©
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ êµ¬í˜„

### í…ŒìŠ¤íŠ¸
- [ ] ê¸°ë³¸ ëŒ€í™” í…ŒìŠ¤íŠ¸
- [ ] ê°ì • ê¸°ë°˜ ì‘ë‹µ í…ŒìŠ¤íŠ¸
- [ ] ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- [ ] TTS ìŒì„± ì¬ìƒ í…ŒìŠ¤íŠ¸
- [ ] ê¸´ ëŒ€í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### ë°°í¬ ì „
- [ ] í”„ë¡œë•ì…˜ ë¹Œë“œ í…ŒìŠ¤íŠ¸
- [ ] í¬ë¡œìŠ¤ ë¸Œë¼ìš°ì € í…ŒìŠ¤íŠ¸ (Chrome, Safari, Firefox)
- [ ] ëª¨ë°”ì¼ ë°˜ì‘í˜• í…ŒìŠ¤íŠ¸
- [ ] ì—ëŸ¬ ë¡œê¹… ì„¤ì •

---

## ì°¸ê³  ë¬¸ì„œ

### ë°±ì—”ë“œ ë¬¸ì„œ
- [AI Voice Chat Guide (Backend)](../../guides/AI_VOICE_CHAT_GUIDE.md)
- [WebSocket Session Handler](../../../services/socket/sessionHandler.js)
- [Gemini Service](../../../services/gemini/gemini.js)

### ì™¸ë¶€ ë¬¸ì„œ
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [React Hooks](https://react.dev/reference/react)

---

**ì‘ì„±ì**: Backend Team
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-01-14
**ë¬¸ì„œ ë²„ì „**: 1.0.0
**ìƒíƒœ**: âœ… Ready for Integration

---

## ğŸ’¬ ì§ˆë¬¸ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?

ë°±ì—”ë“œ íŒ€ì— ë¬¸ì˜í•˜ê±°ë‚˜ [GitHub Issues](https://github.com/KUS-CapstoneDesign-II/BeMoreBackend/issues)ì— ë“±ë¡í•´ì£¼ì„¸ìš”!
