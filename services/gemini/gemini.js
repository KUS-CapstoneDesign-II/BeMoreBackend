const { GoogleGenerativeAI } = require("@google/generative-ai");
const errorHandler = require("../ErrorHandler");
require("dotenv").config();

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// ‚è±Ô∏è Timeout configuration (configurable via environment variable)
const GEMINI_TIMEOUT_MS = parseInt(process.env.GEMINI_TIMEOUT_MS) || 45000; // Default 45 seconds (increased from 30s)

/**
 * Wraps a promise with a timeout mechanism
 * @param {Promise} promise - The promise to wrap
 * @param {number} timeoutMs - Timeout in milliseconds
 * @param {string} operationName - Name of the operation (for error messages)
 * @returns {Promise} Promise that rejects with timeout error if exceeded
 */
function withTimeout(promise, timeoutMs, operationName = 'Operation') {
  return Promise.race([
    promise,
    new Promise((_, reject) =>
      setTimeout(() => {
        reject(new Error(`${operationName} timed out after ${timeoutMs}ms`));
      }, timeoutMs)
    )
  ]);
}

// Mediapipe Ï£ºÏöî ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§
const KEY_INDICES = {
  LEFT_EYE_INNER: 33,
  LEFT_EYE_OUTER: 133,
  RIGHT_EYE_INNER: 362,
  RIGHT_EYE_OUTER: 263,
  NOSE_TIP: 1,
  MOUTH_LEFT_CORNER: 61,
  MOUTH_RIGHT_CORNER: 291,
  CHIN: 152,
  BROW_CENTER: 168,
};

async function analyzeExpression(accumulatedData, speechText = "") {
  if (!accumulatedData || accumulatedData.length === 0) return "Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå";

  // ÏñºÍµ¥ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Ï≤´ Î≤àÏß∏ ÌîÑÎ†àÏûÑÏùÑ Ï¥àÍ∏∞Í∞íÏúºÎ°ú ÏÇ¨Ïö©
  const firstValidFrame = accumulatedData.find(f => f.landmarks && f.landmarks[0]);
  if (!firstValidFrame) return "Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå";
  // ‚úÖ initialLandmarksÎäî Î∞∞Ïó¥ Ï†ÑÏ≤¥Ïó¨Ïïº Ìï® (landmarksHandlerÏóêÏÑú Î∞∞Ïó¥Î°ú Ï†ÄÏû•Îê®)
  const initialLandmarks = firstValidFrame.landmarks;

  // Ï¥àÍ∏∞Í∞í Í≤ÄÏ¶ù
  if (!initialLandmarks || !Array.isArray(initialLandmarks) || initialLandmarks.length === 0) {
    console.error('‚ùå Ï¥àÍ∏∞ ÎûúÎìúÎßàÌÅ¨ ÌòïÏãù Ïò§Î•ò:', {
      exists: !!initialLandmarks,
      isArray: Array.isArray(initialLandmarks),
      length: initialLandmarks?.length
    });
    return "Îç∞Ïù¥ÌÑ∞ ÌòïÏãù Ïò§Î•ò";
  }

  const framesCount = accumulatedData.length;
  const coordinateChanges = {};
  const frameStats = { validFrames: 0, invalidFrames: 0 };

  for (const key in KEY_INDICES) {
    coordinateChanges[key] = { min_y: Infinity, max_y: -Infinity, avg_y: 0, count: 0 };
  }

  // ‚úÖ Îç∞Ïù¥ÌÑ∞ ÏàòÏã† ÌôïÏù∏ Î°úÍ∑∏ (Ï≤´ Î≤àÏß∏ ÌîÑÎ†àÏûÑÎßå)
  console.log(`üìä ÎûúÎìúÎßàÌÅ¨ Î∂ÑÏÑù ÏãúÏûë:`, {
    totalFrames: framesCount,
    initialLandmarkType: typeof initialLandmarks,
    initialLandmarkLength: Array.isArray(initialLandmarks) ? initialLandmarks.length : 'not-array'
  });

  accumulatedData.forEach((frame, frameIdx) => {
    // ‚úÖ FIX: Use full landmarks array directly, not landmarks[0]
    // frame.landmarks is [{x,y,z}, {x,y,z}, ...468] - flat array from frontend
    const face = frame.landmarks;

    // üîç [CRITICAL] Ï≤´ Î≤àÏß∏ ÌîÑÎ†àÏûÑ ÏÉÅÏÑ∏ Í≤ÄÏ¶ù
    if (frameIdx === 0) {
      console.log(`üîç [CRITICAL] First frame validation:`, {
        faceExists: !!face,
        faceType: typeof face,
        faceIsArray: Array.isArray(face),
        faceLength: Array.isArray(face) ? face.length : 'N/A',
        firstPointExample: Array.isArray(face) && face[0] ? { x: face[0].x, y: face[0].y, z: face[0].z } : 'N/A'
      });
    }

    if (!face || !Array.isArray(face) || face.length === 0) {
      frameStats.invalidFrames++;
      if (frameIdx < 3) {
        console.log(`üîç [CRITICAL] Frame ${frameIdx} invalid - face not found or not array`, {
          faceExists: !!face,
          isArray: Array.isArray(face),
          length: face?.length
        });
      }
      return; // ÏñºÍµ¥ ÏóÜÏúºÎ©¥ Í±¥ÎÑàÎúÄ
    }

    let frameHasValidData = false;
    let invalidReasonCount = 0;

    for (const key in KEY_INDICES) {
      const idx = KEY_INDICES[key];

      // ‚úÖ Ï¢åÌëúÍ∞í Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨ Í∞ïÌôî
      const facePoint = face[idx];
      const initPoint = initialLandmarks[idx];

      if (!facePoint || !initPoint) {
        invalidReasonCount++;
        continue;
      }
      if (typeof facePoint.y !== 'number' || typeof initPoint.y !== 'number') {
        invalidReasonCount++;
        if (frameIdx === 0 && key === 'MOUTH_LEFT_CORNER') {
          console.log(`üîç [CRITICAL] Type check failed:`, {
            facePointYType: typeof facePoint.y,
            initPointYType: typeof initPoint.y
          });
        }
        continue;
      }
      if (isNaN(facePoint.y) || isNaN(initPoint.y)) {
        invalidReasonCount++;
        continue;
      }

      const relY = facePoint.y - initPoint.y;

      // ‚úÖ Í≥ÑÏÇ∞ Í≤∞Í≥º Í≤ÄÏ¶ù
      if (isNaN(relY)) {
        invalidReasonCount++;
        continue;
      }

      coordinateChanges[key].min_y = Math.min(coordinateChanges[key].min_y, relY);
      coordinateChanges[key].max_y = Math.max(coordinateChanges[key].max_y, relY);
      coordinateChanges[key].avg_y += relY;
      coordinateChanges[key].count += 1;
      frameHasValidData = true;
    }

    if (frameHasValidData) {
      frameStats.validFrames++;
    } else {
      frameStats.invalidFrames++;
      if (frameIdx < 3) {
        console.log(`üîç [CRITICAL] Frame ${frameIdx} invalid - no valid coordinates (checked ${Object.keys(KEY_INDICES).length} keys)`);
      }
    }
  });

  // ‚úÖ ÌèâÍ∑†Í∞í Í≥ÑÏÇ∞ (Ïú†Ìö®Ìïú Îç∞Ïù¥ÌÑ∞Îßå ÏÇ¨Ïö©)
  for (const key in coordinateChanges) {
    const count = coordinateChanges[key].count;
    if (count > 0) {
      coordinateChanges[key].avg_y /= count;
    } else {
      // ‚úÖ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏúºÎ©¥ Ï¥àÍ∏∞Ìôî
      coordinateChanges[key].min_y = 0;
      coordinateChanges[key].max_y = 0;
      coordinateChanges[key].avg_y = 0;
    }
  }

  // ‚úÖ Î∂ÑÏÑù Í≤∞Í≥º Î°úÍ∑∏
  console.log(`üìä ÎûúÎìúÎßàÌÅ¨ Î∂ÑÏÑù Í≤∞Í≥º:`, {
    validFrames: frameStats.validFrames,
    invalidFrames: frameStats.invalidFrames,
    dataValidityPercent: Math.round((frameStats.validFrames / framesCount) * 100)
  });

  let summaryText = `Ï¥ù ${framesCount}ÌîÑÎ†àÏûÑ ÎèôÏïàÏùò ÏñºÍµ¥ Î≥ÄÌôî ÏöîÏïΩ (Ïú†Ìö®: ${frameStats.validFrames}):\n`;
  for (const key in coordinateChanges) {
    const d = coordinateChanges[key];
    summaryText += `- ${key}: min=${d.min_y.toFixed(3)}, max=${d.max_y.toFixed(3)}, avg=${d.avg_y.toFixed(3)} (count=${d.count})\n`;
  }

  const mouthMove =
    (coordinateChanges.MOUTH_LEFT_CORNER?.max_y || 0) - (coordinateChanges.MOUTH_LEFT_CORNER?.min_y || 0);
  const browMove =
    (coordinateChanges.BROW_CENTER?.max_y || 0) - (coordinateChanges.BROW_CENTER?.min_y || 0);

  summaryText += `ÏûÖ ÏõÄÏßÅÏûÑ Ìè≠=${mouthMove.toFixed(3)}, ÎààÏçπ ÏõÄÏßÅÏûÑ Ìè≠=${browMove.toFixed(3)}\n`;
  console.log("‚úÖ summaryText ÏÉùÏÑ± ÏôÑÎ£å", { mouthMove: mouthMove.toFixed(3), browMove: browMove.toFixed(3) });

  // ‚úÖ Ìñ•ÏÉÅÎêú ÌîÑÎ°¨ÌîÑÌä∏: Îçî ÏÉÅÏÑ∏Ìïú Î∂ÑÏÑù Í∏∞Ï§Ä
  const prompt = `
ÎãπÏã†ÏùÄ ÏñºÍµ¥ ÌëúÏ†ï Î≥ÄÌôî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.

„ÄêÏñºÍµ¥ ÏõÄÏßÅÏûÑ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù„Äë
${summaryText}

„ÄêÎ∞úÌôî ÎÇ¥Ïö©(STT) Î∞è Îß•ÎùΩ„Äë
"${speechText?.trim() || "Î∞úÌôî ÏóÜÏùå"}"

„ÄêÍ∞êÏ†ï Î∂ÑÎ•ò Í∏∞Ï§Ä (Îß§Ïö∞ Ï†ïÌôïÌïòÍ≤å)„Äë

1Ô∏è‚É£ ÌñâÎ≥µ (Happy):
   - ÏûÖÍ∞Ä ÎÅùÏù¥ Ïò¨ÎùºÍ∞ê (max_y > 0.005)
   - ÎààÍ∞Ä Ï£ºÎ¶ÑÏù¥ ÏûàÏùå
   - Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú Î∞ùÏùÄ ÌëúÏ†ï
   Ïòà: mouthMove > 0.007, browMove < 0.002

2Ô∏è‚É£ Ïä¨Ìîî (Sad):
   - ÏûÖÍ∞Ä ÎÅùÏù¥ ÎÇ¥Î†§Í∞ê (max_y < -0.005)
   - ÎààÏçπÏù¥ ÏïàÏ™ΩÏúºÎ°ú Î™®ÏûÑ
   - ÏùåÏÑ±ÏóêÏÑú Ïä¨Ìîà ÌëúÌòÑ ("Ïä¨ÌîÑÎã§", "Ïö∞Ïö∏ÌïòÎã§", "Ïã´Îã§")

3Ô∏è‚É£ Î∂ÑÎÖ∏ (Angry):
   - ÎààÏçπÏù¥ ÍπäÍ≤å Î™®Ïó¨ÏûàÏùå (browMoveÍ∞Ä ÏùåÏàò)
   - ÏûÖÏù¥ Îã§Î¨ºÎ†§ÏûàÍ±∞ÎÇò Ïã¨ÌïòÍ≤å Î≤åÎ†§ÏûàÏùå
   - ÏùåÏÑ±ÏóêÏÑú ÌôîÎÇú ÌëúÌòÑ ("ÌôîÎÇúÎã§", "ÏßúÏ¶ù", "Î∂ÑÎÖ∏")

4Ô∏è‚É£ Î∂àÏïà (Anxious):
   - ÎààÏù¥ ÌÅ¨Í≤å Î≤åÎ†§Ï†∏ ÏûàÏùå
   - ÏûÖÏù¥ Îñ®Î¶º (Î≥ÄÌôîÍ∞Ä Î∂àÍ∑úÏπôÌï®)
   - ÏùåÏÑ±ÏóêÏÑú Î∂àÏïà ÌëúÌòÑ ("Î∂àÏïàÌïòÎã§", "Í±±Ï†ï", "Îñ®Î¶∞Îã§")

5Ô∏è‚É£ Ìù•Î∂Ñ (Excited):
   - ÏûÖÍ≥º ÎààÏù¥ ÌÅ¨Í≤å Î≤åÎ†§Ïßê
   - Î™®Îì† ÌëúÏ†ïÏù¥ ÌÅ¨Í≤å Î≥ÄÌï®
   - ÏùåÏÑ±ÏóêÏÑú Ïã†ÎÇòÎäî ÌëúÌòÑ ("Ïã†ÎÇúÎã§", "Ï¢ãÎã§", "ÏôÄ")

6Ô∏è‚É£ Ï§ëÎ¶Ω (Neutral):
   - ÏûÖÍ≥º Îàà ÏõÄÏßÅÏûÑÏù¥ Í±∞Ïùò ÏóÜÏùå (Î™®Îëê < 0.003)
   - ÏùåÏÑ±ÎèÑ Î¨¥ÌëúÏ†ï ÎòêÎäî Ï§ëÎ¶ΩÏ†Å
   - ÏúÑÏùò Ïñ¥Îñ§ ÌäπÏßïÎèÑ Î™ÖÌôïÌïòÏßÄ ÏïäÏùå

„ÄêÏùëÎãµ ÌòïÏãù„Äë
Îã§Ïùå Í∞êÏ†ï Ï§ë Ï†ïÌôïÌûà ÌïòÎÇòÎßå ÏÑ†ÌÉù:
ÌñâÎ≥µ, Ïä¨Ìîî, Î∂ÑÎÖ∏, Î∂àÏïà, Ìù•Î∂Ñ, Ï§ëÎ¶Ω

ÎßàÌÅ¨Îã§Ïö¥ ÏóÜÏù¥ Ìïú Îã®Ïñ¥Îßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî.
Ïòà: "ÌñâÎ≥µ"
  `;

  try {
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    // ‚è±Ô∏è Wrap with timeout: 30s allows Gemini to respond even after WebSocket closes
    console.log(`üïê [CRITICAL] Starting Gemini request with ${GEMINI_TIMEOUT_MS}ms timeout`);
    const startTime = Date.now();

    const res = await withTimeout(
      model.generateContent(prompt),
      GEMINI_TIMEOUT_MS,
      'Gemini emotion analysis'
    );

    const elapsedTime = Date.now() - startTime;
    console.log(`‚è±Ô∏è [CRITICAL] Gemini response received after ${elapsedTime}ms`);

    const rawResponse = res.response.text().trim().split("\n").pop();
    console.log("Gemini Ï†ÑÏÜ° ÏôÑÎ£å", speechText);
    console.log("üì§ [CRITICAL] Raw Gemini response:", rawResponse);

    // ‚úÖ Í∞êÏ†ï ÌÉÄÏûÖ Ï∂îÏ∂ú (ÌïúÍ∏Ä ‚Üí ÏòÅÎ¨∏) - ÌôïÏû•Îêú Îß§Ìïë
    const emotionMapping = {
      // Happy
      'ÌñâÎ≥µ': 'happy',
      'Í∏∞ÏÅ®': 'happy',
      'Ï¶êÍ±∞ÏõÄ': 'happy',
      'ÏõÉÏùå': 'happy',
      'Ï¢ãÏùå': 'happy',
      'Ïã†ÎÇ®': 'happy',
      'Ï¶êÍ±∞Ïõå': 'happy',
      'ÌñâÎ≥µÌï¥': 'happy',

      // Sad
      'Ïä¨Ìîî': 'sad',
      'Ïö∞Ïö∏': 'sad',
      'Ïä¨Ìçº': 'sad',
      'Ïö∞Ïö∏Ìï¥': 'sad',
      'ÏÑúÎüΩ': 'sad',
      'ÎààÎ¨º': 'sad',
      'ÌûòÎì¶': 'sad',
      'Ïô∏Î°úÏõÄ': 'sad',

      // Angry
      'Î∂ÑÎÖ∏': 'angry',
      'ÌôîÎÇ®': 'angry',
      'ÏßúÏ¶ù': 'angry',
      'ÌôîÎÇò': 'angry',
      'Î∂ÑÎÖ∏Ìï¥': 'angry',
      'ÌôîÎÇ¥': 'angry',
      'ÏÑ±ÎÇ®': 'angry',
      'Í≤©ÎÖ∏': 'angry',

      // Anxious
      'Î∂àÏïà': 'anxious',
      'Í±±Ï†ï': 'anxious',
      'Î∂àÏïàÌï¥': 'anxious',
      'Í±±Ï†ïÎêò': 'anxious',
      'Îñ®Î¶º': 'anxious',
      'Í∏¥Ïû•': 'anxious',
      'Î∂àÌé∏': 'anxious',
      'Ïã†Í≤ΩÏì∞': 'anxious',

      // Excited
      'Ìù•Î∂Ñ': 'excited',
      'Ïã†ÎÇ®': 'excited',
      'Ìù•Î∂ÑÌñà': 'excited',
      'Ïã†ÎÇ¨': 'excited',
      'ÏÑ§Î†ò': 'excited',
      'Îì§Îú∏': 'excited',
      'Ïã†ÎÇò': 'excited',
      'Ìù•Î∂ÑÌï¥': 'excited',

      // Neutral
      'Ï§ëÎ¶Ω': 'neutral',
      'Î¨¥Í∞êÏ†ï': 'neutral',
      'Î¨¥ÌëúÏ†ï': 'neutral',
      'Î≥¥ÌÜµ': 'neutral',
      'ÌèâÏÉÅ': 'neutral',
      'Î≥¥ÌÜµÏù¥': 'neutral',
      'Í¥úÏ∞Æ': 'neutral'
    };

    // rawResponseÏóêÏÑú ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞ (ÎßàÌÅ¨Îã§Ïö¥ Îì±)
    const cleanedResponse = rawResponse.replace(/[*`#\-\[\]"]/g, '').trim();
    console.log(`üîç [CRITICAL] Raw response (cleaned): "${cleanedResponse}"`);
    console.log(`üìä [CRITICAL] Analyzing for emotions from: "${cleanedResponse}"`);

    let detectedEmotion = 'neutral';  // Í∏∞Î≥∏Í∞í
    let foundMatch = false;

    // Ï†ïÌôïÌïú Îã®Ïñ¥ Îß§Ïπ≠ (Í≥µÎ∞±ÏúºÎ°ú Î∂ÑÎ¶¨Îêú Îã®Ïñ¥)
    const words = cleanedResponse.split(/[\s,Ôºå„ÄÅ]/);
    console.log(`üîç [CRITICAL] Split words: ${JSON.stringify(words)}`);

    for (const word of words) {
      if (emotionMapping[word]) {
        detectedEmotion = emotionMapping[word];
        foundMatch = true;
        console.log(`‚úÖ [CRITICAL] Exact word match: "${word}" ‚Üí "${detectedEmotion}"`);
        break;
      }
    }

    // Ìè¨Ìï® Îß§Ïπ≠ (Î∂ÄÎ∂Ñ Î¨∏ÏûêÏó¥ Ìè¨Ìï®)
    if (!foundMatch) {
      for (const [korean, english] of Object.entries(emotionMapping)) {
        if (cleanedResponse.includes(korean)) {
          detectedEmotion = english;
          foundMatch = true;
          console.log(`‚úÖ [CRITICAL] Substring match: "${korean}" found in response ‚Üí "${english}"`);
          break;
        }
      }
    }

    if (!foundMatch) {
      console.log(`‚ö†Ô∏è [CRITICAL] No emotion match found in: "${cleanedResponse}", using default: "neutral"`);
    }

    console.log(`‚úÖ [CRITICAL] Final emotion type: ${detectedEmotion}`, {
      rawResponse: rawResponse.substring(0, 50),
      cleanedResponse: cleanedResponse.substring(0, 50),
      foundMatch
    });
    return detectedEmotion;
  } catch (err) {
    errorHandler.handle(err, {
      module: 'gemini-analysis',
      level: errorHandler.levels.ERROR,
      metadata: {
        framesCount,
        speechTextLength: speechText?.length || 0,
        mouthMove,
        browMove
      }
    });
    return "neutral";  // ÏóêÎü¨ Ïãú Í∏∞Î≥∏Í∞íÏùÑ "Î∂ÑÏÑù Ïã§Ìå®" ÎåÄÏã† "neutral"Î°ú
  }
}

// Simple text-based emotion analysis using Gemini
async function analyzeEmotion(text) {
  const input = (text || '').toString().slice(0, 2000);
  const prompt = `Classify the predominant emotion of the following Korean/English text into one of [happy, sad, angry, anxious, neutral]. Return ONLY the label.\n\nText: "${input}"`;
  try {
    if (!process.env.GEMINI_API_KEY) {
      throw new Error('GEMINI_API_KEY is not set');
    }
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    // ‚è±Ô∏è Apply timeout to simple emotion analysis as well
    const res = await withTimeout(
      model.generateContent(prompt),
      GEMINI_TIMEOUT_MS,
      'Gemini text-based emotion analysis'
    );

    const label = (res?.response?.text?.() || '').trim().toLowerCase();
    const allowed = ['happy','sad','angry','anxious','neutral'];
    return allowed.includes(label) ? label : 'neutral';
  } catch (err) {
    errorHandler.handle(err, { module: 'gemini-emotion', level: errorHandler.levels.ERROR, metadata: { hasKey: !!process.env.GEMINI_API_KEY } });
    return 'neutral';
  }
}

async function generateDetailedReport(accumulatedData, speechText = "") {
  if (!accumulatedData || accumulatedData.length === 0) return { error: 'Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå' };

  // Ïû¨ÏÇ¨Ïö©: Í∞ÑÎã®Ìïú ÏöîÏïΩ ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
  const firstValidFrame = accumulatedData.find(f => f.landmarks && f.landmarks[0]);
  const initialLandmarks = firstValidFrame ? firstValidFrame.landmarks[0] : null;
  const framesCount = accumulatedData.length;
  const coordinateChanges = {};
  for (const key in KEY_INDICES) {
    coordinateChanges[key] = { min_y: Infinity, max_y: -Infinity, avg_y: 0 };
  }
  accumulatedData.forEach((frame) => {
    const face = frame.landmarks?.[0];
    if (!face) return;
    for (const key in KEY_INDICES) {
      const idx = KEY_INDICES[key];
      if (!face[idx] || !initialLandmarks[idx]) continue;
      const relY = face[idx].y - initialLandmarks[idx].y;
      coordinateChanges[key].min_y = Math.min(coordinateChanges[key].min_y, relY);
      coordinateChanges[key].max_y = Math.max(coordinateChanges[key].max_y, relY);
      coordinateChanges[key].avg_y += relY;
    }
  });
  for (const key in coordinateChanges) {
    coordinateChanges[key].avg_y /= framesCount;
  }

  // Íµ¨Ï°∞ÌôîÎêú ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±: Í∞êÏ†ï ÏßÄÌëú, Ïã†Î¢∞ÎèÑ, Í∂åÏû• ÌñâÎèô Îì± (ÎßàÏßÄÎßâ Ï¢ÖÌï© ÏßÄÌëú Ï∂úÎ†• ÏòàÏãú)
  const prompt = `
    ÎãπÏã†ÏùÄ Ïã¨Î¶¨ÏÉÅÎã¥ Î≥¥Ï°∞Î•º ÏúÑÌïú Í∞êÏ†ï Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. ÏïÑÎûò ÌëúÏ†ï ÏöîÏïΩÍ≥º Î∞úÌôî(STT)Î•º ÏÇ¨Ïö©Ìï¥ Íµ¨Ï°∞ÌôîÎêú JSON Î¶¨Ìè¨Ìä∏Î•º ÏÉùÏÑ±ÌïòÏÑ∏Ïöî.

    ÏöîÍµ¨ÏÇ¨Ìï≠:
    - emotion: Ìïú Îã®Ïñ¥(ÌïúÍµ≠Ïñ¥)
    - confidence: 0-1 ÏÇ¨Ïù¥Ïùò Ïã†Î¢∞ÎèÑ ÏàòÏπò
    - indicators: ÌëúÏ†ïÎ≥Ñ(ÏûÖ,ÎààÏçπ Îì±) Í∞ïÎèÑ Ï†êÏàò { name: string, score: 0-1 }
    - recommendation: 1-3Í∞úÏùò Íµ¨Ï≤¥Ï†ÅÏù∏ Ï°∞Ïπò(ÏßßÏùÄ Î¨∏Ïû•)
    - summary: 2-3Î¨∏Ïû• ÏöîÏïΩ ÏÑ§Î™Ö

    [ÌîÑÎ†àÏûÑ Ïàò] ${framesCount}
    [Ï¢åÌëú Î≥ÄÌôî ÏöîÏïΩ]
    ${Object.entries(coordinateChanges).map(([k,v]) => `${k}: min=${v.min_y.toFixed(3)}, max=${v.max_y.toFixed(3)}, avg=${v.avg_y.toFixed(3)}`).join('\n')}

    [STT]
    ${speechText?.trim() ? speechText : 'Î∞úÌôî ÏóÜÏùå'}

    Ï∂úÎ†•ÏùÄ Î∞òÎìúÏãú JSON ÌòïÏãùÏù¥Ïñ¥Ïïº ÌïòÎ©∞, ÏúÑ ÌïÑÎìúÎì§ÏùÑ Ìè¨Ìï®Ìï¥Ïïº Ìï©ÎãàÎã§.
  `;

  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

    // ‚è±Ô∏è Apply timeout to detailed report generation as well
    const res = await withTimeout(
      model.generateContent(prompt),
      GEMINI_TIMEOUT_MS,
      'Gemini detailed report generation'
    );

    // Gemini ÏùëÎãµ ÌååÏã± ÏãúÎèÑ: ÌÖçÏä§Ìä∏ÏóêÏÑú JSON Ï∂îÏ∂ú
    const text = res.response.text().trim();
    // Îπ†Î•∏ ÌååÏã±: ÌÖçÏä§Ìä∏ÏóêÏÑú Ï≤´ Î≤àÏß∏ '{'Î∂ÄÌÑ∞ '}' ÏåçÏùÑ Ï∞æÏïÑ JSON ÌååÏã±
    const jsonStart = text.indexOf('{');
    const jsonEnd = text.lastIndexOf('}');
    if (jsonStart >= 0 && jsonEnd > jsonStart) {
      const jsonStr = text.slice(jsonStart, jsonEnd + 1);
      try {
        const parsed = JSON.parse(jsonStr);
        return { report: parsed, raw: text };
      } catch (parseErr) {
        console.warn('Gemini ÏùëÎãµÏóêÏÑú JSON ÌååÏã± Ïã§Ìå®:', parseErr);
        return { raw: text, error: 'ÌååÏã± Ïã§Ìå®' };
      }
    }

    return { raw: text, error: 'JSON ÎØ∏Ìè¨Ìï® ÏùëÎãµ' };
  } catch (err) {
    console.error('Gemini Error:', err);
    return { error: 'Î∂ÑÏÑù Ïò§Î•ò' };
  }
}

/**
 * Stream AI counseling response with conversation history and emotion context
 * @param {Array} conversationHistory - Array of {role, content} objects
 * @param {string} currentEmotion - Current user emotion (anxious, sad, angry, happy, neutral)
 * @param {Function} onChunk - Callback function for each chunk: (chunk: string) => void
 * @param {Function} onComplete - Callback function on completion: (fullResponse: string) => void
 * @param {Function} onError - Callback function on error: (error: Error) => void
 * @returns {Promise<void>}
 */
async function streamCounselingResponse(conversationHistory, currentEmotion, onChunk, onComplete, onError) {
  try {
    const { buildSystemPrompt, formatConversationHistory } = require('./prompts');

    // Build emotion-based system prompt
    const systemPrompt = buildSystemPrompt(currentEmotion);

    // Format conversation history for Gemini
    const formattedHistory = formatConversationHistory(conversationHistory);

    // Prepare the model with system instructions
    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-flash",
      systemInstruction: systemPrompt,
    });

    // Start chat with history
    const chat = model.startChat({
      history: formattedHistory,
    });

    console.log(`ü§ñ Starting AI streaming response (emotion: ${currentEmotion}, history: ${formattedHistory.length} messages)`);
    const startTime = Date.now();

    // Stream the response
    const result = await withTimeout(
      chat.sendMessageStream("Continue the conversation based on the context above."),
      GEMINI_TIMEOUT_MS,
      'Gemini counseling stream'
    );

    let fullResponse = '';

    // Process each chunk as it arrives
    for await (const chunk of result.stream) {
      const chunkText = chunk.text();
      fullResponse += chunkText;

      // Send chunk to client via callback
      if (onChunk && typeof onChunk === 'function') {
        onChunk(chunkText);
      }
    }

    const elapsedTime = Date.now() - startTime;
    console.log(`‚úÖ AI streaming completed (${elapsedTime}ms, ${fullResponse.length} chars)`);

    // Call completion callback
    if (onComplete && typeof onComplete === 'function') {
      onComplete(fullResponse);
    }

  } catch (err) {
    console.error('‚ùå AI streaming error:', err.message);
    errorHandler.handle(err, {
      module: 'gemini-streaming',
      level: errorHandler.levels.ERROR,
      metadata: {
        emotion: currentEmotion,
        historyLength: conversationHistory?.length || 0,
      },
    });

    // Call error callback
    if (onError && typeof onError === 'function') {
      onError(err);
    }
  }
}

module.exports = { analyzeExpression, generateDetailedReport, analyzeEmotion, streamCounselingResponse };
