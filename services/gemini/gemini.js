const { GoogleGenerativeAI } = require("@google/generative-ai");
const errorHandler = require("../ErrorHandler");
require("dotenv").config();

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// Mediapipe ì£¼ìš” ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
const KEY_INDICES = {
  LEFT_EYE_INNER: 33,
  LEFT_EYE_OUTER: 133,
  RIGHT_EYE_INNER: 362,
  RIGHT_EYE_OUTER: 263,
  NOSE_TIP: 1,
  MOUTH_LEFT_CORNER: 61,
  MOUTH_RIGHT_CORNER: 291,
  CHIN: 152,
  BROW_CENTER: 168,
};

async function analyzeExpression(accumulatedData, speechText = "") {
  if (!accumulatedData || accumulatedData.length === 0) return "ë°ì´í„° ì—†ìŒ";

  // ì–¼êµ´ ë°ì´í„°ê°€ ìˆëŠ” ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©
  const firstValidFrame = accumulatedData.find(f => f.landmarks && f.landmarks[0]);
  if (!firstValidFrame) return "ë°ì´í„° ì—†ìŒ";
  // âœ… initialLandmarksëŠ” ë°°ì—´ ì „ì²´ì—¬ì•¼ í•¨ (landmarksHandlerì—ì„œ ë°°ì—´ë¡œ ì €ì¥ë¨)
  const initialLandmarks = firstValidFrame.landmarks;

  // ì´ˆê¸°ê°’ ê²€ì¦
  if (!initialLandmarks || !Array.isArray(initialLandmarks) || initialLandmarks.length === 0) {
    console.error('âŒ ì´ˆê¸° ëœë“œë§ˆí¬ í˜•ì‹ ì˜¤ë¥˜:', {
      exists: !!initialLandmarks,
      isArray: Array.isArray(initialLandmarks),
      length: initialLandmarks?.length
    });
    return "ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜";
  }

  const framesCount = accumulatedData.length;
  const coordinateChanges = {};
  const frameStats = { validFrames: 0, invalidFrames: 0 };

  for (const key in KEY_INDICES) {
    coordinateChanges[key] = { min_y: Infinity, max_y: -Infinity, avg_y: 0, count: 0 };
  }

  // âœ… ë°ì´í„° ìˆ˜ì‹  í™•ì¸ ë¡œê·¸ (ì²« ë²ˆì§¸ í”„ë ˆì„ë§Œ)
  console.log(`ğŸ“Š ëœë“œë§ˆí¬ ë¶„ì„ ì‹œì‘:`, {
    totalFrames: framesCount,
    initialLandmarkType: typeof initialLandmarks,
    initialLandmarkLength: Array.isArray(initialLandmarks) ? initialLandmarks.length : 'not-array'
  });

  accumulatedData.forEach((frame, frameIdx) => {
    const face = frame.landmarks?.[0];
    if (!face || typeof face !== 'object') {
      frameStats.invalidFrames++;
      return; // ì–¼êµ´ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
    }

    let frameHasValidData = false;
    for (const key in KEY_INDICES) {
      const idx = KEY_INDICES[key];

      // âœ… ì¢Œí‘œê°’ ìœ íš¨ì„± ê²€ì‚¬ ê°•í™”
      const facePoint = face[idx];
      const initPoint = initialLandmarks[idx];

      if (!facePoint || !initPoint) continue;
      if (typeof facePoint.y !== 'number' || typeof initPoint.y !== 'number') continue;
      if (isNaN(facePoint.y) || isNaN(initPoint.y)) continue;

      const relY = facePoint.y - initPoint.y;

      // âœ… ê³„ì‚° ê²°ê³¼ ê²€ì¦
      if (isNaN(relY)) continue;

      coordinateChanges[key].min_y = Math.min(coordinateChanges[key].min_y, relY);
      coordinateChanges[key].max_y = Math.max(coordinateChanges[key].max_y, relY);
      coordinateChanges[key].avg_y += relY;
      coordinateChanges[key].count += 1;
      frameHasValidData = true;
    }

    if (frameHasValidData) frameStats.validFrames++;
    else frameStats.invalidFrames++;
  });

  // âœ… í‰ê· ê°’ ê³„ì‚° (ìœ íš¨í•œ ë°ì´í„°ë§Œ ì‚¬ìš©)
  for (const key in coordinateChanges) {
    const count = coordinateChanges[key].count;
    if (count > 0) {
      coordinateChanges[key].avg_y /= count;
    } else {
      // âœ… ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
      coordinateChanges[key].min_y = 0;
      coordinateChanges[key].max_y = 0;
      coordinateChanges[key].avg_y = 0;
    }
  }

  // âœ… ë¶„ì„ ê²°ê³¼ ë¡œê·¸
  console.log(`ğŸ“Š ëœë“œë§ˆí¬ ë¶„ì„ ê²°ê³¼:`, {
    validFrames: frameStats.validFrames,
    invalidFrames: frameStats.invalidFrames,
    dataValidityPercent: Math.round((frameStats.validFrames / framesCount) * 100)
  });

  let summaryText = `ì´ ${framesCount}í”„ë ˆì„ ë™ì•ˆì˜ ì–¼êµ´ ë³€í™” ìš”ì•½ (ìœ íš¨: ${frameStats.validFrames}):\n`;
  for (const key in coordinateChanges) {
    const d = coordinateChanges[key];
    summaryText += `- ${key}: min=${d.min_y.toFixed(3)}, max=${d.max_y.toFixed(3)}, avg=${d.avg_y.toFixed(3)} (count=${d.count})\n`;
  }

  const mouthMove =
    (coordinateChanges.MOUTH_LEFT_CORNER?.max_y || 0) - (coordinateChanges.MOUTH_LEFT_CORNER?.min_y || 0);
  const browMove =
    (coordinateChanges.BROW_CENTER?.max_y || 0) - (coordinateChanges.BROW_CENTER?.min_y || 0);

  summaryText += `ì… ì›€ì§ì„ í­=${mouthMove.toFixed(3)}, ëˆˆì¹ ì›€ì§ì„ í­=${browMove.toFixed(3)}\n`;
  console.log("âœ… summaryText ìƒì„± ì™„ë£Œ", { mouthMove: mouthMove.toFixed(3), browMove: browMove.toFixed(3) });

  const prompt = `
    ë‹¹ì‹ ì€ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ê°ì •ì„ í•œ ë‹¨ì–´ë¡œ ìš”ì•½í•˜ì„¸ìš”.

    [í‘œì • ë°ì´í„°]
    ${summaryText}

    [ë°œí™” ë‚´ìš©(STT)]
    ${speechText?.trim() ? speechText : "ë°œí™” ì—†ìŒ"}

    ë‹¨ê³„:
    1. í‘œì • ë³€í™”ë¥¼ í•´ì„í•©ë‹ˆë‹¤.
    2. ë°œí™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ê°ì • ë‹¨ì„œë¥¼ ë³´ì™„í•©ë‹ˆë‹¤.
    3. í‘œì •ê³¼ ë°œí™”ë¥¼ ì¢…í•©í•˜ì—¬ ê°ì •ì„ ë‹¨ì–´ í•˜ë‚˜ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
  `;

  try {
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
    const res = await model.generateContent(prompt);
    console.log("Gemini ì „ì†¡ ì™„ë£Œ", speechText);
    return res.response.text().trim().split("\n").pop();
  } catch (err) {
    errorHandler.handle(err, {
      module: 'gemini-analysis',
      level: errorHandler.levels.ERROR,
      metadata: {
        framesCount,
        speechTextLength: speechText?.length || 0,
        mouthMove,
        browMove
      }
    });
    return "ë¶„ì„ ì‹¤íŒ¨";
  }
}

// Simple text-based emotion analysis using Gemini
async function analyzeEmotion(text) {
  const input = (text || '').toString().slice(0, 2000);
  const prompt = `Classify the predominant emotion of the following Korean/English text into one of [happy, sad, angry, anxious, neutral]. Return ONLY the label.\n\nText: "${input}"`;
  try {
    if (!process.env.GEMINI_API_KEY) {
      throw new Error('GEMINI_API_KEY is not set');
    }
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
    const res = await model.generateContent(prompt);
    const label = (res?.response?.text?.() || '').trim().toLowerCase();
    const allowed = ['happy','sad','angry','anxious','neutral'];
    return allowed.includes(label) ? label : 'neutral';
  } catch (err) {
    errorHandler.handle(err, { module: 'gemini-emotion', level: errorHandler.levels.ERROR, metadata: { hasKey: !!process.env.GEMINI_API_KEY } });
    return 'neutral';
  }
}

async function generateDetailedReport(accumulatedData, speechText = "") {
  if (!accumulatedData || accumulatedData.length === 0) return { error: 'ë°ì´í„° ì—†ìŒ' };

  // ì¬ì‚¬ìš©: ê°„ë‹¨í•œ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
  const firstValidFrame = accumulatedData.find(f => f.landmarks && f.landmarks[0]);
  const initialLandmarks = firstValidFrame ? firstValidFrame.landmarks[0] : null;
  const framesCount = accumulatedData.length;
  const coordinateChanges = {};
  for (const key in KEY_INDICES) {
    coordinateChanges[key] = { min_y: Infinity, max_y: -Infinity, avg_y: 0 };
  }
  accumulatedData.forEach((frame) => {
    const face = frame.landmarks?.[0];
    if (!face) return;
    for (const key in KEY_INDICES) {
      const idx = KEY_INDICES[key];
      if (!face[idx] || !initialLandmarks[idx]) continue;
      const relY = face[idx].y - initialLandmarks[idx].y;
      coordinateChanges[key].min_y = Math.min(coordinateChanges[key].min_y, relY);
      coordinateChanges[key].max_y = Math.max(coordinateChanges[key].max_y, relY);
      coordinateChanges[key].avg_y += relY;
    }
  });
  for (const key in coordinateChanges) {
    coordinateChanges[key].avg_y /= framesCount;
  }

  // êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±: ê°ì • ì§€í‘œ, ì‹ ë¢°ë„, ê¶Œì¥ í–‰ë™ ë“± (ë§ˆì§€ë§‰ ì¢…í•© ì§€í‘œ ì¶œë ¥ ì˜ˆì‹œ)
  const prompt = `
    ë‹¹ì‹ ì€ ì‹¬ë¦¬ìƒë‹´ ë³´ì¡°ë¥¼ ìœ„í•œ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í‘œì • ìš”ì•½ê³¼ ë°œí™”(STT)ë¥¼ ì‚¬ìš©í•´ êµ¬ì¡°í™”ëœ JSON ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.

    ìš”êµ¬ì‚¬í•­:
    - emotion: í•œ ë‹¨ì–´(í•œêµ­ì–´)
    - confidence: 0-1 ì‚¬ì´ì˜ ì‹ ë¢°ë„ ìˆ˜ì¹˜
    - indicators: í‘œì •ë³„(ì…,ëˆˆì¹ ë“±) ê°•ë„ ì ìˆ˜ { name: string, score: 0-1 }
    - recommendation: 1-3ê°œì˜ êµ¬ì²´ì ì¸ ì¡°ì¹˜(ì§§ì€ ë¬¸ì¥)
    - summary: 2-3ë¬¸ì¥ ìš”ì•½ ì„¤ëª…

    [í”„ë ˆì„ ìˆ˜] ${framesCount}
    [ì¢Œí‘œ ë³€í™” ìš”ì•½]
    ${Object.entries(coordinateChanges).map(([k,v]) => `${k}: min=${v.min_y.toFixed(3)}, max=${v.max_y.toFixed(3)}, avg=${v.avg_y.toFixed(3)}`).join('\n')}

    [STT]
    ${speechText?.trim() ? speechText : 'ë°œí™” ì—†ìŒ'}

    ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ìœ„ í•„ë“œë“¤ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
  `;

  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
    const res = await model.generateContent(prompt);

    // Gemini ì‘ë‹µ íŒŒì‹± ì‹œë„: í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ
    const text = res.response.text().trim();
    // ë¹ ë¥¸ íŒŒì‹±: í…ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ '{'ë¶€í„° '}' ìŒì„ ì°¾ì•„ JSON íŒŒì‹±
    const jsonStart = text.indexOf('{');
    const jsonEnd = text.lastIndexOf('}');
    if (jsonStart >= 0 && jsonEnd > jsonStart) {
      const jsonStr = text.slice(jsonStart, jsonEnd + 1);
      try {
        const parsed = JSON.parse(jsonStr);
        return { report: parsed, raw: text };
      } catch (parseErr) {
        console.warn('Gemini ì‘ë‹µì—ì„œ JSON íŒŒì‹± ì‹¤íŒ¨:', parseErr);
        return { raw: text, error: 'íŒŒì‹± ì‹¤íŒ¨' };
      }
    }

    return { raw: text, error: 'JSON ë¯¸í¬í•¨ ì‘ë‹µ' };
  } catch (err) {
    console.error('Gemini Error:', err);
    return { error: 'ë¶„ì„ ì˜¤ë¥˜' };
  }
}

module.exports = { analyzeExpression, generateDetailedReport, analyzeEmotion };
